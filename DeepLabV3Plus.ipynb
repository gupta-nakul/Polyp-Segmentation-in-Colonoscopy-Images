{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AJdDOUYTg_O4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_753656/2761976175.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import resize\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W16M9ez2mSYn",
    "outputId": "519c8183-cd89-4507-f04e-9b5335835db1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24800 24800\n"
     ]
    }
   ],
   "source": [
    "def create_images_list(path):\n",
    "    full_path = []\n",
    "    images = sorted(os.listdir(path))\n",
    "\n",
    "    for i in images:\n",
    "        full_path.append(os.path.join(path, i))\n",
    "\n",
    "    return full_path\n",
    "\n",
    "\n",
    "train_images = create_images_list('./datasets/kvasir_segmentation_dataset/kvasir_segmentation_dataset/train/images')\n",
    "train_masks = create_images_list('./datasets/kvasir_segmentation_dataset/kvasir_segmentation_dataset/train/masks')\n",
    "\n",
    "valid_images = create_images_list('./datasets/kvasir_segmentation_dataset/kvasir_segmentation_dataset/valid/images')\n",
    "valid_masks = create_images_list('./datasets/kvasir_segmentation_dataset/kvasir_segmentation_dataset/valid/masks')\n",
    "\n",
    "print(len(train_images), len(train_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CoZ4vIkmtFQu"
   },
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame({'image': train_images, 'mask': train_masks})\n",
    "val_data = pd.DataFrame({'image': valid_images, 'mask': valid_masks})\n",
    "\n",
    "train_data = shuffle(train_data).reset_index().drop(columns=['index'])\n",
    "val_data = shuffle(val_data).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mIs1LeC0ebHv"
   },
   "outputs": [],
   "source": [
    "X_train = train_data['image']\n",
    "y_train = train_data['mask']\n",
    "\n",
    "X_validation = val_data['image']\n",
    "y_validation = val_data['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kkZs8YOdsZSW"
   },
   "outputs": [],
   "source": [
    "SEED = 69\n",
    "IMG_SIZE = 256,256\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "85Bmybl0E3HA"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, img_size):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.mask_paths = list(mask_paths)\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.transform_image = transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.transform_mask = transforms.Compose([\n",
    "            transforms.Resize(self.img_size, interpolation=Image.NEAREST),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.image_paths):\n",
    "            raise IndexError(f\"Index {idx} out of range for dataset with length {len(self.image_paths)}.\")\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        image = self.transform_image(image)\n",
    "        mask = self.transform_mask(mask)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PRoWLQvVE4o7"
   },
   "outputs": [],
   "source": [
    "# Assuming image and mask paths are stored in X_data, y_data for training\n",
    "# and X_validation, y_validation for validation\n",
    "train_dataset = CustomDataset(X_train, y_train, IMG_SIZE)\n",
    "validation_dataset = CustomDataset(X_validation, y_validation, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_zxeM4T9FjXs"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "NUM_WORKERS = 4  # Based on your system's capability\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "58Cc9FTKSCGL"
   },
   "outputs": [],
   "source": [
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g-5Ltz6xSV4M"
   },
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "    def __init__(self, channels: int, ratio: int = 8) -> None:\n",
    "        super(SEModule, self).__init__()\n",
    "\n",
    "        # Average Pooling for Squeeze\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Excitation Operation\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // ratio),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.LeakyReLU(negative_slope=0.1, inplace=True),\n",
    "            nn.Linear(channels // ratio, channels),\n",
    "            nn.Sigmoid(),\n",
    "            # nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Any) -> Any:\n",
    "        # Squeeze & Excite Forward Pass\n",
    "        b, c, _, _ = x.size()\n",
    "\n",
    "        y = self.avgpool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "\n",
    "        # For Tanh\n",
    "        # y_normalized = (y + 1) * 0.5\n",
    "\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "40tUoutoSVzZ"
   },
   "outputs": [],
   "source": [
    "class ASPPModule(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, dilations: list[int]) -> None:\n",
    "        super(ASPPModule, self).__init__()\n",
    "\n",
    "        # Atrous Convolutions\n",
    "        self.atrous_convs = nn.ModuleList()\n",
    "        for d in dilations:\n",
    "            at_conv = nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size=3, dilation=d, padding=\"same\", bias=False\n",
    "            )\n",
    "            self.atrous_convs.append(at_conv)\n",
    "\n",
    "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.squeeze_excite = SEModule(channels=out_channels)\n",
    "        # self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # Upsampling by Bilinear Interpolation\n",
    "        self.upsample = nn.UpsamplingBilinear2d(scale_factor=16)\n",
    "        # Global Average Pooling\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(16, 16))\n",
    "        # 1x1 Convolution\n",
    "        self.conv1x1 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1, padding=\"same\", bias=False\n",
    "        )\n",
    "\n",
    "        # Final 1x1 Convolution\n",
    "        self.final_conv = nn.Conv2d(\n",
    "            in_channels=out_channels * (len(dilations) + 2),\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=1,\n",
    "            padding=\"same\",\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Any) -> Any:\n",
    "        # ASPP Forward Pass\n",
    "\n",
    "        # 1x1 Convolution\n",
    "        x1 = self.conv1x1(x)\n",
    "        x1 = self.batch_norm(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        # x1 = self.leaky_relu(x1)\n",
    "        x1 = self.squeeze_excite(x1)\n",
    "\n",
    "        # Atrous Convolutions\n",
    "        atrous_outputs = []\n",
    "        for at_conv in self.atrous_convs:\n",
    "            at_output = at_conv(x)\n",
    "            at_output = self.batch_norm(at_output)\n",
    "            at_output = self.relu(at_output)\n",
    "            # at_output = self.leaky_relu(at_output)\n",
    "            at_output = self.squeeze_excite(at_output)\n",
    "            atrous_outputs.append(at_output)\n",
    "\n",
    "        # Global Average Pooling and 1x1 Convolution for global context\n",
    "        avg_pool = self.avgpool(x)\n",
    "        avg_pool = self.conv1x1(avg_pool)\n",
    "        avg_pool = self.batch_norm(avg_pool)\n",
    "        avg_pool = self.relu(avg_pool)\n",
    "        # avg_pool = self.leaky_relu(avg_pool)\n",
    "        avg_pool = self.upsample(avg_pool)\n",
    "        avg_pool = self.squeeze_excite(avg_pool)\n",
    "\n",
    "        # Concatenating Dilated Convolutions and Global Average Pooling\n",
    "        combined_output = torch.cat((x1, *atrous_outputs, avg_pool), dim=1)\n",
    "\n",
    "        # Final 1x1 Convolution for ASPP Output\n",
    "        aspp_output = self.final_conv(combined_output)\n",
    "        aspp_output = self.batch_norm(aspp_output)\n",
    "        aspp_output = self.relu(aspp_output)\n",
    "        # aspp_output = self.leaky_relu(aspp_output)\n",
    "        aspp_output = self.squeeze_excite(aspp_output)\n",
    "\n",
    "        return aspp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7XykU1RaSVqk"
   },
   "outputs": [],
   "source": [
    "class DecoderModule(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super(DecoderModule, self).__init__()\n",
    "\n",
    "        # Squeeze and Excite Module\n",
    "        self.squeeze_excite = SEModule(channels=304)\n",
    "        self.squeeze_excite2 = SEModule(channels=out_channels)\n",
    "        self.squeeze_excite3 = SEModule(channels=48)\n",
    "        # 1x1 Convolution\n",
    "        self.conv_low = nn.Conv2d(in_channels, 48, kernel_size=1, padding=\"same\", bias=False)\n",
    "        self.batch_norm = nn.BatchNorm2d(48)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        # self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # 3x3 Convolution\n",
    "        self.final_conv1 = nn.Conv2d(\n",
    "            in_channels=304, out_channels=256, kernel_size=3, padding=\"same\", bias=False\n",
    "        )\n",
    "        # 3x3 Convolution\n",
    "        self.final_conv2 = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=3, padding=\"same\", bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, x_high: Any, x_low: Any) -> Any:\n",
    "        # Decoder Forward Pass\n",
    "\n",
    "        # 1x1 Convolution on Low-Level Features\n",
    "        x_low = self.conv_low(x_low)\n",
    "        x_low = self.batch_norm(x_low)\n",
    "        x_low = self.dropout(x_low)\n",
    "        x_low = self.relu(x_low)\n",
    "        # x_low = self.leaky_relu(x_low)\n",
    "        x_low = self.squeeze_excite3(x_low)\n",
    "\n",
    "        # Concatenating High-Level and Low-Level Features\n",
    "        x = torch.cat((x_high, x_low), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.squeeze_excite(x)\n",
    "\n",
    "        # 3x3 Convolution on Concatenated Feature Map\n",
    "        x = self.final_conv1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.leaky_relu(x)\n",
    "        x = self.squeeze_excite2(x)\n",
    "\n",
    "        # 3x3 Convolution on Concatenated Feature Map\n",
    "        x = self.final_conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        # x = self.leaky_relu(x)\n",
    "        x = self.squeeze_excite2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Gm8OkTHZRfZ5"
   },
   "outputs": [],
   "source": [
    "class DeepLabV3Plus(nn.Module):\n",
    "    def __init__(self, num_classes: int = 1) -> None:\n",
    "        super(DeepLabV3Plus, self).__init__()\n",
    "        resnet = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        in_channels = 1024\n",
    "        out_channels = 256\n",
    "        # Dilation Rates\n",
    "        dilations = [6, 12, 18, 24]\n",
    "        # ASPP Module\n",
    "        self.aspp = ASPPModule(in_channels, out_channels, dilations)\n",
    "        # Decoder Module\n",
    "        self.decoder = DecoderModule(out_channels, out_channels)\n",
    "        # Upsampling with Bilinear Interpolation\n",
    "        self.upsample = nn.UpsamplingBilinear2d(scale_factor=4)\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        # Final 1x1 Convolution\n",
    "        self.final_conv = nn.Conv2d(out_channels, num_classes, kernel_size=1)\n",
    "        # Sigmoid Activation for Binary-Seg\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        # self.tanh = nn.Tanh()\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: Any) -> Any:\n",
    "        # DeepLabV3+ Forward Pass\n",
    "        # Getting Low-Level Features\n",
    "        x_low = self.backbone[:-3](x)\n",
    "        # Getting Image Features from Backbone\n",
    "        x = self.backbone[:-1](x)\n",
    "        # ASPP forward pass - High-Level Features\n",
    "        x = self.aspp(x)\n",
    "        # Upsampling High-Level Features\n",
    "        x = self.upsample(x)\n",
    "        x = self.dropout(x)\n",
    "        # Decoder forward pass - Concatenating Features\n",
    "        x = self.decoder(x, x_low)\n",
    "        # Upsampling Concatenated Features from Decoder\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        # Final 1x1 Convolution for Binary-Segmentation\n",
    "        x = self.final_conv(x)\n",
    "        x = self.sigmoid(x)\n",
    "        # x = self.tanh(x)\n",
    "\n",
    "        # For Tanh\n",
    "        # normalized_x = (x + 1) * 0.5\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7N32Zv8LTRXz",
    "outputId": "7f61adca-fc5b-45bd-c5da-0546c979b656"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepLabV3Plus(num_classes=1)  # For binary segmentation, num_classes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3Plus(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aspp): ASPPModule(\n",
       "    (atrous_convs): ModuleList(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(6, 6), bias=False)\n",
       "      (1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(12, 12), bias=False)\n",
       "      (2): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(18, 18), bias=False)\n",
       "      (3): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(24, 24), bias=False)\n",
       "    )\n",
       "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (squeeze_excite): SEModule(\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (upsample): UpsamplingBilinear2d(scale_factor=16.0, mode='bilinear')\n",
       "    (avgpool): AvgPool2d(kernel_size=(16, 16), stride=(16, 16), padding=0)\n",
       "    (conv1x1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "    (final_conv): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "  )\n",
       "  (decoder): DecoderModule(\n",
       "    (squeeze_excite): SEModule(\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=304, out_features=38, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=38, out_features=304, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (squeeze_excite2): SEModule(\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=32, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (squeeze_excite3): SEModule(\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=48, out_features=6, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Linear(in_features=6, out_features=48, bias=True)\n",
       "        (3): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "    (conv_low): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), padding=same, bias=False)\n",
       "    (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (batch_norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (final_conv1): Conv2d(304, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "    (final_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
       "  )\n",
       "  (upsample): UpsamplingBilinear2d(scale_factor=4.0, mode='bilinear')\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (final_conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Eul44ooYUvCB"
   },
   "outputs": [],
   "source": [
    "SMOOTH = 1e-8\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred_mask: Any, true_mask: Any) -> torch.Tensor:\n",
    "        intersection = torch.sum(pred_mask * true_mask)\n",
    "        union = torch.sum(pred_mask) + torch.sum(true_mask)\n",
    "\n",
    "        # Add a small epsilon to the denominator to avoid division by zero\n",
    "        dice_loss = 1.0 - (2.0 * intersection + SMOOTH) / (union + SMOOTH)\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "iTUuGO2vUMWA"
   },
   "outputs": [],
   "source": [
    "model = DeepLabV3Plus(num_classes=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = DiceLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", patience=3, factor=0.1, verbose=True\n",
    ")\n",
    "\n",
    "# For Early-Stopping\n",
    "patience_epochs = 20\n",
    "no_improvement_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "7n-sM7CDW3N_"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_mask: Any, true_mask: Any) -> torch.Tensor:\n",
    "    pred_mask = pred_mask.float()\n",
    "    true_mask = true_mask.float()\n",
    "\n",
    "    intersection = torch.sum(pred_mask * true_mask)\n",
    "    union = torch.sum((pred_mask + true_mask) > 0.5)\n",
    "\n",
    "    # Add a small epsilon to the denominator to avoid division by zero\n",
    "    iou = (intersection + SMOOTH) / (union + SMOOTH)\n",
    "    dice_coefficient = (2 * intersection + SMOOTH) / (\n",
    "        torch.sum(pred_mask) + torch.sum(true_mask) + SMOOTH\n",
    "    )\n",
    "    pixel_accuracy = torch.sum(pred_mask == true_mask) / true_mask.numel()\n",
    "\n",
    "    return iou.item(), dice_coefficient.item(), pixel_accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3ZrrLozlWf94"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "IHyKFSmjWjMI"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCuRs0rCWPCx",
    "outputId": "b14f05f1-6448-4af4-99d3-b3b806f6dd3b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 3100/3100 [05:29<00:00,  9.40batch/s, loss=0.517, lr=0.0001, train_dice_coef=0.483, train_iou=0.319, train_pix_acc=0.809] \n",
      "Validation: 100%|██████████| 13/13 [00:00<00:00, 15.59batch/s, lr=0.0001, val_dice_coef=0.606, val_iou=0.435, val_loss=0.393, val_pix_acc=0.839]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50\n",
      "Avg Train Loss: 0.4589\n",
      "Avg Validation Loss: 0.4081\n",
      "Avg IoU Train: 0.3807\n",
      "Avg IoU Val: 0.4283\n",
      "Avg Pix Acc Train: 0.5415\n",
      "Avg Pix Acc Val: 0.8325\n",
      "Avg Dice Coeff Train: 0.5415\n",
      "Avg Dice Coeff Val: 0.5932\n",
      "Current LR: 0.0001\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 3100/3100 [07:33<00:00,  6.84batch/s, loss=0.401, lr=0.0001, train_dice_coef=0.6, train_iou=0.429, train_pix_acc=0.874]   \n",
      "Validation: 100%|██████████| 13/13 [00:01<00:00, 11.25batch/s, lr=0.0001, val_dice_coef=0.699, val_iou=0.538, val_loss=0.305, val_pix_acc=0.87] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50\n",
      "Avg Train Loss: 0.3515\n",
      "Avg Validation Loss: 0.3409\n",
      "Avg IoU Train: 0.4910\n",
      "Avg IoU Val: 0.5040\n",
      "Avg Pix Acc Train: 0.6489\n",
      "Avg Pix Acc Val: 0.8491\n",
      "Avg Dice Coeff Train: 0.6489\n",
      "Avg Dice Coeff Val: 0.6630\n",
      "Current LR: 0.0001\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 3100/3100 [10:45<00:00,  4.81batch/s, loss=0.149, lr=0.0001, train_dice_coef=0.853, train_iou=0.743, train_pix_acc=0.944] \n",
      "Validation: 100%|██████████| 13/13 [00:01<00:00, 11.36batch/s, lr=0.0001, val_dice_coef=0.737, val_iou=0.584, val_loss=0.268, val_pix_acc=0.898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50\n",
      "Avg Train Loss: 0.2554\n",
      "Avg Validation Loss: 0.2420\n",
      "Avg IoU Train: 0.6057\n",
      "Avg IoU Val: 0.6221\n",
      "Avg Pix Acc Train: 0.7453\n",
      "Avg Pix Acc Val: 0.9049\n",
      "Avg Dice Coeff Train: 0.7453\n",
      "Avg Dice Coeff Val: 0.7624\n",
      "Current LR: 0.0001\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 3100/3100 [11:00<00:00,  4.69batch/s, loss=0.283, lr=0.0001, train_dice_coef=0.718, train_iou=0.561, train_pix_acc=0.885] \n",
      "Validation: 100%|██████████| 13/13 [00:01<00:00, 11.33batch/s, lr=0.0001, val_dice_coef=0.814, val_iou=0.686, val_loss=0.189, val_pix_acc=0.926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50\n",
      "Avg Train Loss: 0.2003\n",
      "Avg Validation Loss: 0.2102\n",
      "Avg IoU Train: 0.6781\n",
      "Avg IoU Val: 0.6678\n",
      "Avg Pix Acc Train: 0.8006\n",
      "Avg Pix Acc Val: 0.9196\n",
      "Avg Dice Coeff Train: 0.8006\n",
      "Avg Dice Coeff Val: 0.7944\n",
      "Current LR: 0.0001\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 3100/3100 [11:06<00:00,  4.65batch/s, loss=0.182, lr=0.0001, train_dice_coef=0.819, train_iou=0.694, train_pix_acc=0.919] \n",
      "Validation: 100%|██████████| 13/13 [00:01<00:00, 11.31batch/s, lr=0.0001, val_dice_coef=0.797, val_iou=0.663, val_loss=0.212, val_pix_acc=0.923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50\n",
      "Avg Train Loss: 0.1651\n",
      "Avg Validation Loss: 0.2277\n",
      "Avg IoU Train: 0.7270\n",
      "Avg IoU Val: 0.6419\n",
      "Avg Pix Acc Train: 0.8358\n",
      "Avg Pix Acc Val: 0.9203\n",
      "Avg Dice Coeff Train: 0.8358\n",
      "Avg Dice Coeff Val: 0.7770\n",
      "Current LR: 0.0001\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 3100/3100 [10:59<00:00,  4.70batch/s, loss=0.117, lr=0.0001, train_dice_coef=0.884, train_iou=0.792, train_pix_acc=0.922] \n",
      "Validation: 100%|██████████| 13/13 [00:01<00:00, 11.35batch/s, lr=0.0001, val_dice_coef=0.855, val_iou=0.748, val_loss=0.145, val_pix_acc=0.942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/50\n",
      "Avg Train Loss: 0.1458\n",
      "Avg Validation Loss: 0.2033\n",
      "Avg IoU Train: 0.7554\n",
      "Avg IoU Val: 0.6737\n",
      "Avg Pix Acc Train: 0.8551\n",
      "Avg Pix Acc Val: 0.9253\n",
      "Avg Dice Coeff Train: 0.8551\n",
      "Avg Dice Coeff Val: 0.7986\n",
      "Current LR: 0.0001\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 3100/3100 [11:00<00:00,  4.70batch/s, loss=0.0602, lr=0.0001, train_dice_coef=0.94, train_iou=0.887, train_pix_acc=0.956] \n",
      "Validation: 100%|██████████| 13/13 [00:01<00:00, 11.45batch/s, lr=0.0001, val_dice_coef=0.839, val_iou=0.723, val_loss=0.162, val_pix_acc=0.941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50\n",
      "Avg Train Loss: 0.1272\n",
      "Avg Validation Loss: 0.2840\n",
      "Avg IoU Train: 0.7835\n",
      "Avg IoU Val: 0.5693\n",
      "Avg Pix Acc Train: 0.8737\n",
      "Avg Pix Acc Val: 0.9098\n",
      "Avg Dice Coeff Train: 0.8737\n",
      "Avg Dice Coeff Val: 0.7154\n",
      "Current LR: 0.0001\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50:  55%|█████▍    | 1690/3100 [06:00<04:59,  4.70batch/s, loss=0.0874, lr=0.0001, train_dice_coef=0.913, train_iou=0.841, train_pix_acc=0.933]"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # TRAINING\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total_iou_train = 0.0\n",
    "    total_pixel_accuracy_train = 0.0\n",
    "    total_dice_coefficient_train = 0.0\n",
    "\n",
    "    train_loader = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\"\n",
    "    )\n",
    "\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        t_loss = criterion(outputs, masks)\n",
    "\n",
    "        t_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += t_loss.item()\n",
    "\n",
    "        # Calculating metrics for training\n",
    "        with torch.no_grad():\n",
    "            pred_masks = outputs > 0.5\n",
    "            iou_train, dice_coefficient_train, pixel_accuracy_train = calculate_metrics(\n",
    "                pred_masks, masks\n",
    "            )\n",
    "\n",
    "            total_iou_train += iou_train\n",
    "            total_dice_coefficient_train += dice_coefficient_train\n",
    "            total_pixel_accuracy_train += pixel_accuracy_train\n",
    "\n",
    "        # Displaying metrics in the progress bar description\n",
    "        train_loader.set_postfix(\n",
    "            loss=t_loss.item(),\n",
    "            train_iou=iou_train,\n",
    "            train_pix_acc=pixel_accuracy_train,\n",
    "            train_dice_coef=dice_coefficient_train,\n",
    "            lr=current_lr,\n",
    "        )\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    avg_iou_train = total_iou_train / len(train_loader)\n",
    "    avg_pixel_accuracy_train = total_pixel_accuracy_train / len(train_loader)\n",
    "    avg_dice_coefficient_train = total_dice_coefficient_train / len(train_loader)\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_iou_val = 0.0\n",
    "    total_pixel_accuracy_val = 0.0\n",
    "    total_dice_coefficient_val = 0.0\n",
    "\n",
    "    test_dataloader = tqdm(validation_loader, desc=f\"Validation\", unit=\"batch\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            v_loss = criterion(outputs, masks)\n",
    "            val_loss += v_loss.item()\n",
    "\n",
    "            # Calculating metrics for Validation\n",
    "            pred_masks = outputs > 0.5\n",
    "            iou_val, dice_coefficient_val, pixel_accuracy_val = calculate_metrics(\n",
    "                pred_masks, masks\n",
    "            )\n",
    "\n",
    "            total_iou_val += iou_val\n",
    "            total_pixel_accuracy_val += pixel_accuracy_val\n",
    "            total_dice_coefficient_val += dice_coefficient_val\n",
    "\n",
    "            # Displaying metrics in progress bar description\n",
    "            test_dataloader.set_postfix(\n",
    "                val_loss=v_loss.item(),\n",
    "                val_iou=iou_val,\n",
    "                val_pix_acc=pixel_accuracy_val,\n",
    "                val_dice_coef=dice_coefficient_val,\n",
    "                lr=current_lr,\n",
    "            )\n",
    "\n",
    "    val_loss /= len(test_dataloader)\n",
    "    avg_iou_val = total_iou_val / len(test_dataloader)\n",
    "    avg_pixel_accuracy_val = total_pixel_accuracy_val / len(test_dataloader)\n",
    "    avg_dice_coefficient_val = total_dice_coefficient_val / len(test_dataloader)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch {epoch + 1}/{num_epochs}\\n\"\n",
    "        f\"Avg Train Loss: {train_loss:.4f}\\n\"\n",
    "        f\"Avg Validation Loss: {val_loss:.4f}\\n\"\n",
    "        f\"Avg IoU Train: {avg_iou_train:.4f}\\n\"\n",
    "        f\"Avg IoU Val: {avg_iou_val:.4f}\\n\"\n",
    "        f\"Avg Pix Acc Train: {avg_dice_coefficient_train:.4f}\\n\"\n",
    "        f\"Avg Pix Acc Val: {avg_pixel_accuracy_val:.4f}\\n\"\n",
    "        f\"Avg Dice Coeff Train: {avg_dice_coefficient_train:.4f}\\n\"\n",
    "        f\"Avg Dice Coeff Val: {avg_dice_coefficient_val:.4f}\\n\"\n",
    "        f\"Current LR: {current_lr}\\n\"\n",
    "        f\"{'-'*50}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'deeplabv3plus.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DeepLabV3Plus(num_classes=1)\n",
    "# model.load_state_dict(torch.load('deeplabv3plus.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVMUhYU7WO_X"
   },
   "outputs": [],
   "source": [
    "test_images = create_images_list('./datasets/kvasir_segmentation_dataset/kvasir_segmentation_dataset/test/images')\n",
    "test_masks = create_images_list('./datasets/kvasir_segmentation_dataset/kvasir_segmentation_dataset/test/masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUY2E-j_ew7w"
   },
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame({'image': test_images, 'mask': test_masks})\n",
    "test_data = shuffle(test_data).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFvOjJVvowMn"
   },
   "outputs": [],
   "source": [
    "X_test = test_data['image']\n",
    "y_test = test_data['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eB6NCae7omDl"
   },
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(X_test, y_test, IMG_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PolynbUpG-p",
    "outputId": "c04e3302-0cb7-4a01-b554-46687ec32e98"
   },
   "outputs": [],
   "source": [
    "test_loader = tqdm(test_loader, desc=\"Evaluation\", unit=\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NH1LH1f_xBUy",
    "outputId": "7ee2c534-0835-4d8a-e4bc-3fb188d5801a"
   },
   "outputs": [],
   "source": [
    "# Additional imports\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "def evaluate_model(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_iou = 0.0\n",
    "    total_dice = 0.0\n",
    "    total_accuracy = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Threshold outputs to create binary mask\n",
    "            preds = outputs > 0.5\n",
    "\n",
    "            # Calculate metrics\n",
    "            iou, dice_coefficient, pixel_accuracy = calculate_metrics(preds, masks)\n",
    "\n",
    "            total_iou += iou\n",
    "            total_dice += dice_coefficient\n",
    "            total_accuracy += pixel_accuracy\n",
    "            num_samples += 1\n",
    "\n",
    "    avg_loss = total_loss / num_samples\n",
    "    avg_iou = total_iou / num_samples\n",
    "    avg_dice = total_dice / num_samples\n",
    "    avg_accuracy = total_accuracy / num_samples\n",
    "\n",
    "    return avg_loss, avg_iou, avg_dice, avg_accuracy\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "avg_loss, avg_iou, avg_dice, avg_accuracy = evaluate_model(test_loader, model, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "print(f\"Test IoU: {avg_iou:.4f}\")\n",
    "print(f\"Test Dice Coefficient: {avg_dice:.4f}\")\n",
    "print(f\"Test Pixel Accuracy: {avg_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR3qxi30qCr5"
   },
   "outputs": [],
   "source": [
    "def save_overlay_image(img_path: str, mask_path: str, prediction: Any, overlay_path: str) -> None:\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    resized_image = cv2.resize(image, (256,256), interpolation = cv2.INTER_AREA)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    resized_mask = cv2.resize(mask, (256,256), interpolation = cv2.INTER_AREA)\n",
    "    line = np.ones((256, 10, 3)) * 128\n",
    "\n",
    "    resized_mask = np.expand_dims(resized_mask, axis=-1)\n",
    "    resized_mask = np.concatenate([resized_mask, resized_mask, resized_mask], axis=-1)\n",
    "\n",
    "    prediction = np.expand_dims(prediction, axis=-1)\n",
    "    prediction = np.concatenate([prediction, prediction, prediction], axis=-1)\n",
    "\n",
    "    overlay = np.multiply(resized_image, prediction)\n",
    "    prediction = prediction * 255\n",
    "\n",
    "    final_img = np.concatenate([resized_image, line, resized_mask, line, prediction, line, overlay], axis=1)\n",
    "\n",
    "    cv2.imwrite(overlay_path, final_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjaRUZehsA_R"
   },
   "outputs": [],
   "source": [
    "output_dir = './output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "G7p4SZ6qpG6P",
    "outputId": "9cfd6d8f-8fba-4b22-fd44-3ab680f14ca6"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (image, _) in enumerate(test_loader):\n",
    "        image = image.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        prediction = output.cpu().numpy()[0, 0]\n",
    "\n",
    "        img_path = test_dataset.image_paths[i]\n",
    "        mask_path = test_dataset.mask_paths[i]\n",
    "\n",
    "        output_img_name = img_path.split('/')[-1][:-4]\n",
    "\n",
    "        output_img_path = os.path.join(output_dir, f\"output_{output_img_name}.png\")\n",
    "\n",
    "        save_overlay_image(img_path, mask_path, prediction, output_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-xMziRp7x-J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
